{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Text Classification using Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abeda\\anaconda3\\envs\\NC\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:56:10,163 https://nlp.informatik.hu-berlin.de/resources/models/sentiment-curated-distilbert/sentiment-en-mix-distillbert_4.pt not found in cache, downloading to C:\\Users\\abeda\\AppData\\Local\\Temp\\tmpe01erp79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253M/253M [00:29<00:00, 9.02MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:56:39,900 copying C:\\Users\\abeda\\AppData\\Local\\Temp\\tmpe01erp79 to cache at C:\\Users\\abeda\\.flair\\models\\sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 11:56:41,430 removing temp file C:\\Users\\abeda\\AppData\\Local\\Temp\\tmpe01erp79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 4.01kB/s]\n",
      "Downloading config.json: 100%|██████████| 483/483 [00:00<00:00, 51.0kB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.81MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 2.01MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence above is:  ['Sentence[5]: \"Flair is pretty neat!\"'/'POSITIVE' (0.9997)]\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "sentence = Sentence('Flair is pretty neat!')\n",
    "classifier.predict(sentence)\n",
    "# print sentence with predicted labels\n",
    "print('Sentence above is: ', sentence.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"./spam.csv\", encoding='latin-1').sample(frac=1).drop_duplicates()\n",
    "data = data[['v1', 'v2']].rename(columns={\"v1\":\"label\", \"v2\":\"text\"})\n",
    " \n",
    "data['label'] = '__label__' + data['label'].astype(str)\n",
    "train_data, temp_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "test_data, dev_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "#\n",
    "train_data.to_csv('train.csv', index=False, header=False)\n",
    "test_data.to_csv('test.csv', index=False, header=False)\n",
    "dev_data.to_csv('dev.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:42:08,128 Reading data from .\n",
      "2023-11-18 14:42:08,129 Train: train.csv\n",
      "2023-11-18 14:42:08,130 Dev: dev.csv\n",
      "2023-11-18 14:42:08,132 Test: test.csv\n",
      "2023-11-18 14:42:17,614 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "4135it [00:03, 1176.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:42:21,248 Dictionary created for label 'binary' with 2 values: __label__ham (seen 3627 times), __label__spam (seen 508 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 14:42:21,351 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 14:42:21,360 Model: \"TextClassifier(\n",
      "  (embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings(\n",
      "        'glove'\n",
      "        (embedding): Embedding(400001, 100)\n",
      "      )\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2023-11-18 14:42:21,362 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 14:42:21,364 Corpus: 4135 train + 517 dev + 517 test sentences\n",
      "2023-11-18 14:42:21,365 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 14:42:21,371 Train:  4135 sentences\n",
      "2023-11-18 14:42:21,373         (train_with_dev=False, train_with_test=False)\n",
      "2023-11-18 14:42:21,374 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 14:42:21,377 Training Params:\n",
      "2023-11-18 14:42:21,378  - learning_rate: \"0.1\" \n",
      "2023-11-18 14:42:21,382  - mini_batch_size: \"32\"\n",
      "2023-11-18 14:42:21,387  - max_epochs: \"10\"\n",
      "2023-11-18 14:42:21,389  - shuffle: \"True\"\n",
      "2023-11-18 14:42:21,391 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 14:42:21,392 Plugins:\n",
      "2023-11-18 14:42:21,394  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'\n",
      "2023-11-18 14:42:21,395 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 14:42:21,397 Final evaluation on model from best epoch (best-model.pt)\n",
      "2023-11-18 14:42:21,398  - metric: \"('micro avg', 'f1-score')\"\n",
      "2023-11-18 14:42:21,400 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 14:42:21,404 Computation:\n",
      "2023-11-18 14:42:21,405  - compute on device: cpu\n",
      "2023-11-18 14:42:21,407  - embedding storage: cpu\n",
      "2023-11-18 14:42:21,411 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 14:42:21,413 Model training base path: \".\"\n",
      "2023-11-18 14:42:21,415 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 14:42:21,417 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 14:43:39,367 epoch 1 - iter 13/130 - loss 0.33194163 - time (sec): 77.94 - samples/sec: 5.34 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 14:45:28,211 epoch 1 - iter 26/130 - loss 0.25821114 - time (sec): 186.79 - samples/sec: 4.45 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 14:47:01,674 epoch 1 - iter 39/130 - loss 0.23171778 - time (sec): 280.25 - samples/sec: 4.45 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 14:49:06,801 epoch 1 - iter 52/130 - loss 0.21198642 - time (sec): 405.38 - samples/sec: 4.10 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 14:50:43,620 epoch 1 - iter 65/130 - loss 0.21093803 - time (sec): 502.19 - samples/sec: 4.14 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 14:52:17,797 epoch 1 - iter 78/130 - loss 0.19519221 - time (sec): 596.37 - samples/sec: 4.19 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 14:53:27,088 epoch 1 - iter 91/130 - loss 0.19606242 - time (sec): 665.66 - samples/sec: 4.37 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 14:55:00,157 epoch 1 - iter 104/130 - loss 0.18876536 - time (sec): 758.73 - samples/sec: 4.39 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 14:56:32,278 epoch 1 - iter 117/130 - loss 0.18015370 - time (sec): 850.85 - samples/sec: 4.40 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 14:58:19,513 epoch 1 - iter 130/130 - loss 0.17286868 - time (sec): 958.09 - samples/sec: 4.32 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 14:58:19,515 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 14:58:19,517 EPOCH 1 done: loss 0.1729 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:40<00:00, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:00:00,007 DEV : loss 0.07366844266653061 - f1-score (micro avg)  0.9749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:00:00,863  - 0 epochs without improvement\n",
      "2023-11-18 15:00:00,870 saving best model\n",
      "2023-11-18 15:00:08,567 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 15:01:30,247 epoch 2 - iter 13/130 - loss 0.20817400 - time (sec): 81.68 - samples/sec: 5.09 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:03:31,449 epoch 2 - iter 26/130 - loss 0.14953756 - time (sec): 202.88 - samples/sec: 4.10 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:04:38,469 epoch 2 - iter 39/130 - loss 0.13878335 - time (sec): 269.90 - samples/sec: 4.62 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:06:07,277 epoch 2 - iter 52/130 - loss 0.13833769 - time (sec): 358.69 - samples/sec: 4.64 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:07:25,229 epoch 2 - iter 65/130 - loss 0.12716593 - time (sec): 436.66 - samples/sec: 4.76 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:08:41,597 epoch 2 - iter 78/130 - loss 0.12576482 - time (sec): 513.03 - samples/sec: 4.87 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:09:53,776 epoch 2 - iter 91/130 - loss 0.11671362 - time (sec): 585.20 - samples/sec: 4.98 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:11:16,026 epoch 2 - iter 104/130 - loss 0.11428270 - time (sec): 667.45 - samples/sec: 4.99 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:12:48,385 epoch 2 - iter 117/130 - loss 0.11530118 - time (sec): 759.80 - samples/sec: 4.93 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:14:01,805 epoch 2 - iter 130/130 - loss 0.11321287 - time (sec): 833.23 - samples/sec: 4.96 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:14:01,810 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 15:14:01,812 EPOCH 2 done: loss 0.1132 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:53<00:00, 12.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:15:55,810 DEV : loss 0.14561548829078674 - f1-score (micro avg)  0.9671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:15:56,320  - 1 epochs without improvement\n",
      "2023-11-18 15:15:56,329 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 15:17:04,201 epoch 3 - iter 13/130 - loss 0.07777318 - time (sec): 67.87 - samples/sec: 6.13 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:18:28,801 epoch 3 - iter 26/130 - loss 0.07965225 - time (sec): 152.47 - samples/sec: 5.46 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:20:17,566 epoch 3 - iter 39/130 - loss 0.08343975 - time (sec): 261.24 - samples/sec: 4.78 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:21:42,310 epoch 3 - iter 52/130 - loss 0.08263643 - time (sec): 345.98 - samples/sec: 4.81 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:23:22,778 epoch 3 - iter 65/130 - loss 0.08852240 - time (sec): 446.45 - samples/sec: 4.66 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:24:56,336 epoch 3 - iter 78/130 - loss 0.08869940 - time (sec): 540.00 - samples/sec: 4.62 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:26:17,240 epoch 3 - iter 91/130 - loss 0.08889401 - time (sec): 620.91 - samples/sec: 4.69 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:27:52,199 epoch 3 - iter 104/130 - loss 0.09636698 - time (sec): 715.87 - samples/sec: 4.65 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:29:36,231 epoch 3 - iter 117/130 - loss 0.09849933 - time (sec): 819.90 - samples/sec: 4.57 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:30:51,756 epoch 3 - iter 130/130 - loss 0.09728799 - time (sec): 895.42 - samples/sec: 4.62 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:30:51,761 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 15:30:51,763 EPOCH 3 done: loss 0.0973 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:47<00:00, 11.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:32:39,886 DEV : loss 0.1329948902130127 - f1-score (micro avg)  0.9691\n",
      "2023-11-18 15:32:47,872  - 2 epochs without improvement\n",
      "2023-11-18 15:32:47,877 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 15:33:51,616 epoch 4 - iter 13/130 - loss 0.06608791 - time (sec): 63.74 - samples/sec: 6.53 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:35:14,497 epoch 4 - iter 26/130 - loss 0.07341333 - time (sec): 146.62 - samples/sec: 5.67 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:37:00,315 epoch 4 - iter 39/130 - loss 0.07480845 - time (sec): 252.44 - samples/sec: 4.94 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:39:01,595 epoch 4 - iter 52/130 - loss 0.06911221 - time (sec): 373.72 - samples/sec: 4.45 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:40:04,255 epoch 4 - iter 65/130 - loss 0.06515349 - time (sec): 436.38 - samples/sec: 4.77 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:41:43,952 epoch 4 - iter 78/130 - loss 0.06600261 - time (sec): 536.07 - samples/sec: 4.66 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:43:12,869 epoch 4 - iter 91/130 - loss 0.07024207 - time (sec): 624.99 - samples/sec: 4.66 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:44:37,739 epoch 4 - iter 104/130 - loss 0.07111976 - time (sec): 709.86 - samples/sec: 4.69 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:45:41,407 epoch 4 - iter 117/130 - loss 0.07534410 - time (sec): 773.53 - samples/sec: 4.84 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:46:53,844 epoch 4 - iter 130/130 - loss 0.07773900 - time (sec): 845.96 - samples/sec: 4.89 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:46:53,852 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 15:46:53,853 EPOCH 4 done: loss 0.0777 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:36<00:00, 10.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:48:30,858 DEV : loss 0.06594043225049973 - f1-score (micro avg)  0.9807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:48:31,337  - 0 epochs without improvement\n",
      "2023-11-18 15:48:31,344 saving best model\n",
      "2023-11-18 15:48:36,012 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 15:50:06,818 epoch 5 - iter 13/130 - loss 0.04932607 - time (sec): 90.79 - samples/sec: 4.58 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:51:21,819 epoch 5 - iter 26/130 - loss 0.05488776 - time (sec): 165.79 - samples/sec: 5.02 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:52:53,474 epoch 5 - iter 39/130 - loss 0.06397169 - time (sec): 257.45 - samples/sec: 4.85 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:54:10,420 epoch 5 - iter 52/130 - loss 0.06581747 - time (sec): 334.40 - samples/sec: 4.98 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:55:25,505 epoch 5 - iter 65/130 - loss 0.06365768 - time (sec): 409.48 - samples/sec: 5.08 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:56:53,253 epoch 5 - iter 78/130 - loss 0.07018622 - time (sec): 497.23 - samples/sec: 5.02 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:58:13,719 epoch 5 - iter 91/130 - loss 0.06715474 - time (sec): 577.69 - samples/sec: 5.04 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 15:59:51,468 epoch 5 - iter 104/130 - loss 0.06557695 - time (sec): 675.44 - samples/sec: 4.93 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:01:19,708 epoch 5 - iter 117/130 - loss 0.07024985 - time (sec): 763.68 - samples/sec: 4.90 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:02:59,610 epoch 5 - iter 130/130 - loss 0.06992111 - time (sec): 863.59 - samples/sec: 4.79 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:02:59,613 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 16:02:59,615 EPOCH 5 done: loss 0.0699 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:38<00:00, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:04:38,330 DEV : loss 0.054292455315589905 - f1-score (micro avg)  0.9865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:04:39,173  - 0 epochs without improvement\n",
      "2023-11-18 16:04:39,183 saving best model\n",
      "2023-11-18 16:04:45,011 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 16:06:00,117 epoch 6 - iter 13/130 - loss 0.08398009 - time (sec): 75.08 - samples/sec: 5.54 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:07:25,754 epoch 6 - iter 26/130 - loss 0.09877393 - time (sec): 160.71 - samples/sec: 5.18 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:08:40,438 epoch 6 - iter 39/130 - loss 0.08631973 - time (sec): 235.40 - samples/sec: 5.30 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:10:37,409 epoch 6 - iter 52/130 - loss 0.07480164 - time (sec): 352.34 - samples/sec: 4.72 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:11:43,407 epoch 6 - iter 65/130 - loss 0.08398159 - time (sec): 418.37 - samples/sec: 4.97 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:13:45,988 epoch 6 - iter 78/130 - loss 0.08264567 - time (sec): 540.95 - samples/sec: 4.61 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:15:03,232 epoch 6 - iter 91/130 - loss 0.07300120 - time (sec): 618.19 - samples/sec: 4.71 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:16:19,953 epoch 6 - iter 104/130 - loss 0.06818326 - time (sec): 694.91 - samples/sec: 4.79 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:17:49,725 epoch 6 - iter 117/130 - loss 0.06739541 - time (sec): 784.69 - samples/sec: 4.77 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:19:04,708 epoch 6 - iter 130/130 - loss 0.06998618 - time (sec): 859.67 - samples/sec: 4.81 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:19:04,717 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 16:19:04,719 EPOCH 6 done: loss 0.0700 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:41<00:00, 11.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:20:46,538 DEV : loss 0.0837271586060524 - f1-score (micro avg)  0.9807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:20:47,002  - 1 epochs without improvement\n",
      "2023-11-18 16:20:47,011 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 16:22:06,522 epoch 7 - iter 13/130 - loss 0.04334944 - time (sec): 79.51 - samples/sec: 5.23 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:23:52,393 epoch 7 - iter 26/130 - loss 0.05076186 - time (sec): 185.38 - samples/sec: 4.49 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:25:22,796 epoch 7 - iter 39/130 - loss 0.05020794 - time (sec): 275.78 - samples/sec: 4.53 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:26:36,155 epoch 7 - iter 52/130 - loss 0.04991535 - time (sec): 349.14 - samples/sec: 4.77 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:27:36,225 epoch 7 - iter 65/130 - loss 0.04959641 - time (sec): 409.21 - samples/sec: 5.08 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:28:42,382 epoch 7 - iter 78/130 - loss 0.06013009 - time (sec): 475.37 - samples/sec: 5.25 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:29:57,426 epoch 7 - iter 91/130 - loss 0.06231994 - time (sec): 550.40 - samples/sec: 5.29 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:31:30,770 epoch 7 - iter 104/130 - loss 0.05593341 - time (sec): 643.76 - samples/sec: 5.17 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:32:49,340 epoch 7 - iter 117/130 - loss 0.06055976 - time (sec): 722.33 - samples/sec: 5.18 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:33:54,487 epoch 7 - iter 130/130 - loss 0.05944993 - time (sec): 787.48 - samples/sec: 5.25 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:33:54,495 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 16:33:54,497 EPOCH 7 done: loss 0.0594 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:38<00:00, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:35:33,300 DEV : loss 0.07611437141895294 - f1-score (micro avg)  0.9826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:35:33,863  - 2 epochs without improvement\n",
      "2023-11-18 16:35:33,870 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 16:36:37,962 epoch 8 - iter 13/130 - loss 0.07202913 - time (sec): 64.09 - samples/sec: 6.49 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:37:56,264 epoch 8 - iter 26/130 - loss 0.05974300 - time (sec): 142.39 - samples/sec: 5.84 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:39:24,492 epoch 8 - iter 39/130 - loss 0.04967935 - time (sec): 230.62 - samples/sec: 5.41 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:40:35,100 epoch 8 - iter 52/130 - loss 0.06661782 - time (sec): 301.23 - samples/sec: 5.52 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:41:59,792 epoch 8 - iter 65/130 - loss 0.06405137 - time (sec): 385.92 - samples/sec: 5.39 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:43:09,237 epoch 8 - iter 78/130 - loss 0.06492869 - time (sec): 455.36 - samples/sec: 5.48 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:44:21,049 epoch 8 - iter 91/130 - loss 0.06391510 - time (sec): 527.18 - samples/sec: 5.52 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:45:50,116 epoch 8 - iter 104/130 - loss 0.05867480 - time (sec): 616.23 - samples/sec: 5.40 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:47:00,770 epoch 8 - iter 117/130 - loss 0.05959250 - time (sec): 686.90 - samples/sec: 5.45 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:47:58,615 epoch 8 - iter 130/130 - loss 0.05920514 - time (sec): 744.74 - samples/sec: 5.55 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:47:58,617 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 16:47:58,618 EPOCH 8 done: loss 0.0592 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:28<00:00,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:49:27,419 DEV : loss 0.06449711322784424 - f1-score (micro avg)  0.9865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 16:49:29,501  - 3 epochs without improvement\n",
      "2023-11-18 16:49:29,506 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 16:50:35,836 epoch 9 - iter 13/130 - loss 0.05020331 - time (sec): 66.33 - samples/sec: 6.27 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:51:48,554 epoch 9 - iter 26/130 - loss 0.05896274 - time (sec): 139.05 - samples/sec: 5.98 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:53:00,950 epoch 9 - iter 39/130 - loss 0.05583865 - time (sec): 211.44 - samples/sec: 5.90 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:54:03,955 epoch 9 - iter 52/130 - loss 0.05523768 - time (sec): 274.45 - samples/sec: 6.06 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:55:19,190 epoch 9 - iter 65/130 - loss 0.05404725 - time (sec): 349.68 - samples/sec: 5.95 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:56:31,840 epoch 9 - iter 78/130 - loss 0.05398000 - time (sec): 422.33 - samples/sec: 5.91 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:58:10,057 epoch 9 - iter 91/130 - loss 0.05107662 - time (sec): 520.55 - samples/sec: 5.59 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 16:59:24,635 epoch 9 - iter 104/130 - loss 0.04617380 - time (sec): 595.13 - samples/sec: 5.59 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 17:00:59,968 epoch 9 - iter 117/130 - loss 0.04470267 - time (sec): 690.46 - samples/sec: 5.42 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 17:02:05,528 epoch 9 - iter 130/130 - loss 0.05040368 - time (sec): 756.02 - samples/sec: 5.47 - lr: 0.100000 - momentum: 0.000000\n",
      "2023-11-18 17:02:05,536 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 17:02:05,537 EPOCH 9 done: loss 0.0504 - lr: 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:26<00:00,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:03:32,291 DEV : loss 0.08021838217973709 - f1-score (micro avg)  0.9865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:03:32,695  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.05]\n",
      "2023-11-18 17:03:32,699 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 17:04:43,337 epoch 10 - iter 13/130 - loss 0.04096822 - time (sec): 70.64 - samples/sec: 5.89 - lr: 0.050000 - momentum: 0.000000\n",
      "2023-11-18 17:05:47,982 epoch 10 - iter 26/130 - loss 0.04002469 - time (sec): 135.28 - samples/sec: 6.15 - lr: 0.050000 - momentum: 0.000000\n",
      "2023-11-18 17:07:06,217 epoch 10 - iter 39/130 - loss 0.04492460 - time (sec): 213.52 - samples/sec: 5.85 - lr: 0.050000 - momentum: 0.000000\n",
      "2023-11-18 17:08:21,124 epoch 10 - iter 52/130 - loss 0.04509313 - time (sec): 288.42 - samples/sec: 5.77 - lr: 0.050000 - momentum: 0.000000\n",
      "2023-11-18 17:09:23,223 epoch 10 - iter 65/130 - loss 0.03697921 - time (sec): 350.52 - samples/sec: 5.93 - lr: 0.050000 - momentum: 0.000000\n",
      "2023-11-18 17:11:09,597 epoch 10 - iter 78/130 - loss 0.03682438 - time (sec): 456.90 - samples/sec: 5.46 - lr: 0.050000 - momentum: 0.000000\n",
      "2023-11-18 17:12:30,399 epoch 10 - iter 91/130 - loss 0.03391379 - time (sec): 537.70 - samples/sec: 5.42 - lr: 0.050000 - momentum: 0.000000\n",
      "2023-11-18 17:14:02,808 epoch 10 - iter 104/130 - loss 0.03130816 - time (sec): 630.11 - samples/sec: 5.28 - lr: 0.050000 - momentum: 0.000000\n",
      "2023-11-18 17:15:12,931 epoch 10 - iter 117/130 - loss 0.03521452 - time (sec): 700.23 - samples/sec: 5.35 - lr: 0.050000 - momentum: 0.000000\n",
      "2023-11-18 17:16:39,749 epoch 10 - iter 130/130 - loss 0.03586086 - time (sec): 787.05 - samples/sec: 5.25 - lr: 0.050000 - momentum: 0.000000\n",
      "2023-11-18 17:16:39,753 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 17:16:39,754 EPOCH 10 done: loss 0.0359 - lr: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:29<00:00,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:18:09,751 DEV : loss 0.08240685611963272 - f1-score (micro avg)  0.9826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:18:10,539  - 1 epochs without improvement\n",
      "2023-11-18 17:18:15,445 ----------------------------------------------------------------------------------------------------\n",
      "2023-11-18 17:18:15,450 Loading model from best epoch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:26<00:00,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18 17:19:45,080 \n",
      "Results:\n",
      "- F-score (micro) 0.9884\n",
      "- F-score (macro) 0.9749\n",
      "- Accuracy 0.9884\n",
      "\n",
      "By class:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " __label__ham     0.9889    0.9978    0.9933       446\n",
      "__label__spam     0.9851    0.9296    0.9565        71\n",
      "\n",
      "     accuracy                         0.9884       517\n",
      "    macro avg     0.9870    0.9637    0.9749       517\n",
      " weighted avg     0.9884    0.9884    0.9883       517\n",
      "\n",
      "2023-11-18 17:19:45,081 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.988394584139265}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "# load corpus by pointing to folder. Train, dev and test gets identified automatically\n",
    "label_type ='binary'\n",
    "column_name_map = {0: \"label\", 1: \"text\"}\n",
    "corpus: Corpus = CSVClassificationCorpus(data_folder=Path('./'),\n",
    "                                        column_name_map=column_name_map,\n",
    "                                        skip_header=False,\n",
    "                                        label_type ='binary')\n",
    "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
    "\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(label_type=label_type),label_type=label_type, multi_label=False)\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.train('./', max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sentence[10]: \"Many thanks for your application to join the team...\"'/'__label__ham' (0.9988)]\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "classifier = TextClassifier.load('./best-model.pt')\n",
    "sentence = Sentence('Many thanks for your application to join the team...')\n",
    "classifier.predict(sentence)\n",
    "print(sentence.labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
